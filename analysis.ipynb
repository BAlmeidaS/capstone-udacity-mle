{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Analysis - Object Detection\n",
    "\n",
    "This notebook is about the exploratory data analysis to Object Detection project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import project.download_content as content\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import notebooks_utils.analysis as utils\n",
    "from notebooks_utils import visuals\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# This notebook uses plotly orca to create the images\n",
    "from plotly.io import orca\n",
    "\n",
    "orca.config.executable = 'orca'\n",
    "orca.config.port = 9091\n",
    "orca.config.default_scale = 5\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "sns.set_palette(sns.diverging_palette(255, 133, l=60, n=12, center=\"dark\"))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis starts with the downloading of all the data. To do this, you could use the makefile created. Just open the terminal, go to where you clone this project and run `make download-content`, following the instructions to download files.\n",
    "\n",
    "**To run this analysis and reproduced it, you must download the METADATA files**. Besides that, in some cells, it is necessary to download the images (TRAIN, TEST, and VALIDATION image files). Because of that, to reproduce this analysis entirely, you should download these files also (download around 550Gb). If you did not download them, these cells are not going to run entirely, but the cell will notify you about this, and the process is going to follow.\n",
    "\n",
    "The analysis made with all the images files downloaded could be accessed in an HTML file that is in the project, called \"analysis.html\". You do not need to download all images to see it, open the file in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Gathering all files\n",
    "if not content.does_metadata_exist():\n",
    "    raise OSError(f'There are metadata file(s) that did not downloaded yet...')\n",
    "print('All Metadata files exist...')\n",
    "\n",
    "METAPATH = os.path.join(content.DATAPATH, 'METADATA')\n",
    "\n",
    "# metadata general files\n",
    "print('Gathering all metadata files...', end='')\n",
    "\n",
    "df_classes_raw = pd.read_csv(METAPATH + \"/class-descriptions-boxable.csv\",\n",
    "                             names=['class_encode', 'class_name'])\n",
    "with open(METAPATH + \"/bbox_labels_600_hierarchy.json\") as f:\n",
    "    dict_hierarchy_raw = json.load(f)\n",
    "print('OK!')\n",
    "\n",
    "\n",
    "# train files\n",
    "print('Gathering all train files...', end='')\n",
    "df_train_bbox_raw = pd.read_csv(METAPATH + \"/train-annotations-bbox.csv\")\n",
    "df_train_labels_raw = pd.read_csv(\n",
    "    METAPATH + \"/train-annotations-human-imagelabels-boxable.csv\")\n",
    "print('OK!')\n",
    "\n",
    "\n",
    "# validation files\n",
    "print('Gathering all validation files...', end='')\n",
    "df_val_bbox_raw = pd.read_csv(METAPATH + \"/validation-annotations-bbox.csv\")\n",
    "df_val_labels_raw = pd.read_csv(\n",
    "    METAPATH + \"/validation-annotations-human-imagelabels-boxable.csv\")\n",
    "print('OK!')\n",
    "\n",
    "\n",
    "# test files\n",
    "print('Gathering all test files...', end='')\n",
    "df_test_bbox_raw = pd.read_csv(METAPATH + \"/test-annotations-bbox.csv\")\n",
    "df_test_labels_raw = pd.read_csv(\n",
    "    METAPATH + \"/test-annotations-human-imagelabels-boxable.csv\")\n",
    "print('OK!')\n",
    "\n",
    "# downloaded images\n",
    "if utils.all_images_downloaded():\n",
    "    print(\"Gathering labels of all images downloaded...\", end='')\n",
    "    df_images_train = utils.images_downloaded('TRAIN')\n",
    "    df_images_val = utils.images_downloaded('VALIDATION')\n",
    "    df_images_test = utils.images_downloaded('TEST')\n",
    "    print('Ok!')\n",
    "else:\n",
    "    print(\"\"\"\n",
    "Unfortunately you did not download the files...\n",
    "That's ok, you can follow, but some cells will not run properly.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "heading_collapsed": true
   },
   "source": [
    "### Assess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Explaining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is crucial to start the analysis to understand all the files downloaded.\n",
    "\n",
    "When you run the command `make download-content`, you should notice that the files are divided into four blocks, METADATA, TRAIN, VALIDATION, and TEST.\n",
    "\n",
    "The blocks TRAIN, VALIDATION, and TEST are about the images files, and there is nothing but that, the images.\n",
    "\n",
    "**The block METADATA is a must-have content**. In it, we are going to find eight files.\n",
    "\n",
    "**The first six files are essentially a split of two data**, the bounding box annotations *([type]-annotations-bbox.csv)* and the image-level annotations *([type]-annotations-human-imagelabels-boxable.csv)*.\n",
    "\n",
    "Image-level Annotations are manual data labeled by a human (from google and a crowdsourced system). These labels try to represent what the image has. More about this dataset could be found in [here](https://storage.googleapis.com/openimages/web/factsfigures.html) in session **Image-level Labels**.\n",
    "\n",
    "The Bounding Box Annotation is a dataset that defines, for each image, where are the objects annotated previously by the Image-level Annotation. These annotations are focused on the most specific labels in Image-level Annotations. More about this dataset could be founded [here](https://storage.googleapis.com/openimages/web/factsfigures.html) in session **Bonding Boxes**. \n",
    "\n",
    "These two datasets described above were divided by Google in three sets. Train, which is going to be used to train the model, Validation, which is going to be used to compare the models, and Test, which is going to be used to do the final evaluation of the chosen one model.\n",
    "\n",
    "The final two files are about the classes themselves.\n",
    "\n",
    "All the labels described in the paragraphs above are encoded representations of the classes. The CSV *class-descriptions-boxable.csv* maps each **encoded class name** (machine-understandable) **to a semantic class name** (human-understandable).\n",
    "\n",
    "Lastly, the JSON file *bbox_labels_600_hierarchy.json* **describes a hierarchical tree of all classes**, describing a hierarchy of each class. This file shows us, for example, that Woman derives from Person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Assessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#number of images by dataset\n",
    "print(f\"\"\"Number of bouding boxes: {(df_train_bbox_raw.shape[0]\n",
    "                                     + df_val_bbox_raw.shape[0]\n",
    "                                     + df_test_bbox_raw.shape[0]):,}\"\"\", end=\"\\n\"*2)\n",
    "\n",
    "print(f\"labels in train images: {df_train_labels_raw.shape[0]:,}\")\n",
    "print(f\"labels in validation images: {df_val_labels_raw.shape[0]:,}\")\n",
    "print(f\"labels in test images: {df_test_labels_raw.shape[0]:,}\", end=\"\\n\"*2)\n",
    "\n",
    "print(f\"bouding boxes labeled in train: {df_train_bbox_raw.shape[0]:,}\")\n",
    "print(f\"bouding boxes labeled in validation: {df_val_bbox_raw.shape[0]:,}\")\n",
    "print(f\"bouding boxes labeled in test: {df_test_bbox_raw.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "utils.check_images_download()\n",
    "\n",
    "print(f\"images downloaded in train: {df_images_train.shape[0]:,}\")\n",
    "print(f\"images downloaded in validation: {df_images_val.shape[0]:,}\")\n",
    "print(f\"images downloaded in test: {df_images_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Explaining more about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Classes Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# display classes and their encodes\n",
    "print(f\"total classes: {df_classes_raw.shape[0]}\")\n",
    "df_classes_raw.sample(2, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the cell above, all datasets are described:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show info about all dfs\n",
    "for k, df in {'Train Bounding Boxes': df_train_bbox_raw,\n",
    "              'Train Labels': df_train_labels_raw,\n",
    "              'Validation Bounding Boxes': df_val_bbox_raw,\n",
    "              'Validation Labels': df_val_labels_raw,\n",
    "              'Test Bounding Boxes': df_test_bbox_raw,\n",
    "              'Test Labels': df_test_labels_raw}.items():\n",
    "    print(f\"####### {k.upper()} #######\", end=\"\\n\"*2)\n",
    "    print(f\"shape: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "    print(f\"duplicated values: {df[df.duplicated(keep='first')].shape[0]} records\",\n",
    "          end=\"\\n\"*2)\n",
    "\n",
    "    print(\"Unique Values:\")\n",
    "    for col in df.columns:\n",
    "        print(\n",
    "            f\"   {str(col)+' ':-<15} {str(df[col].dtype).upper()+' ':-<10} Nulls = {df[col].isna().sum():,} | Uniques = {df[col].nunique():,}\")\n",
    "    display(df.sample(2, random_state=37))\n",
    "    print('_'*80, end=\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Classes Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "code_folding": [],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# classes hierarchy\n",
    "\n",
    "num_classes, classes = utils.count_recursive(dict_hierarchy_raw)\n",
    "\n",
    "print(f\"There are {num_classes} classes in the JSON hierarchy\",\n",
    "      end=\"\\n\"*2)\n",
    "\n",
    "print(\"The first node class encode is:\",\n",
    "      dict_hierarchy_raw['LabelName'], end=\"\\n\"*2)\n",
    "\n",
    "# defining a node to consult\n",
    "i=17\n",
    "\n",
    "print(f\"the {i}th son encode of the first node:\",\n",
    "      dict_hierarchy_raw['Subcategory'][i]['LabelName'])\n",
    "print(f\"The sons of the {i}th node:\")\n",
    "for subcat in dict_hierarchy_raw['Subcategory'][i]['Subcategory']:\n",
    "    print(f\"   {subcat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# finding with some class in hierarchial has no human representation\n",
    "for encoded_name in classes:\n",
    "    try:\n",
    "        semantic_name = utils.semantic_name(encoded_name)\n",
    "    except KeyError:\n",
    "        print(f\"{encoded_name} - 'Undefined Human Representation'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Import to notice that only the first node (\"the father of all\") has no semantic representation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### About labels and image downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# assess the images downloaded\n",
    "utils.check_images_download()\n",
    "\n",
    "print('### Number of unique images in each dataframe ###', end='\\n'*2)\n",
    "train_labels   = pd.DataFrame(df_train_labels_raw.ImageID.unique(), columns=['ImageID'])\n",
    "train_bbox     = pd.DataFrame(df_train_bbox_raw.ImageID.unique(), columns=['ImageID'])\n",
    "train_download = pd.DataFrame(df_images_train.index, columns=['ImageID'])\n",
    "\n",
    "print(f\"{'images in train images-level ':-<40}> {train_labels.shape[0]:,}\")\n",
    "print(f\"{'images in train bbox ':-<40}> {train_bbox.shape[0]:,}\")\n",
    "print(f\"{'images in train download folder ':-<40}> {train_download.shape[0]:,}\",\n",
    "      end='\\n'*2)\n",
    "\n",
    "val_labels   = pd.DataFrame(df_val_labels_raw.ImageID.unique(), columns=['ImageID'])\n",
    "val_bbox     = pd.DataFrame(df_val_bbox_raw.ImageID.unique(), columns=['ImageID'])\n",
    "val_download = pd.DataFrame(df_images_val.index, columns=['ImageID'])\n",
    "\n",
    "print(f\"{'images in validation images-level ':-<40}> {val_labels.shape[0]:,}\")\n",
    "print(f\"{'images in validation bbox ':-<40}> {val_bbox.shape[0]:,}\")\n",
    "print(f\"{'images in valitation download folder ':-<40}> {val_download.shape[0]:,}\",\n",
    "      end='\\n'*2)\n",
    "\n",
    "test_labels   = pd.DataFrame(df_test_labels_raw.ImageID.unique(), columns=['ImageID'])\n",
    "test_bbox     = pd.DataFrame(df_test_bbox_raw.ImageID.unique(), columns=['ImageID'])\n",
    "test_download = pd.DataFrame(df_images_test.index, columns=['ImageID'])\n",
    "\n",
    "print(f\"{'images in test images-level ':-<40}> {test_labels.shape[0]:,}\")\n",
    "print(f\"{'images in test bbox ':-<40}> {test_bbox.shape[0]:,}\")\n",
    "print(f\"{'images in test donwload folder ':-<40}> {test_download.shape[0]:,}\",\n",
    "      end='\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# joining train dfs\n",
    "train_labels['label'] = True\n",
    "train_bbox['bbox'] = True\n",
    "train_download['download'] = True\n",
    "\n",
    "df_train_imgs = (train_download.merge(train_labels, on='ImageID', how='outer')\n",
    "                               .merge(train_bbox, on='ImageID', how='outer'))\n",
    "df_train_imgs.fillna(False, inplace=True)\n",
    "\n",
    "# joining validation dfs\n",
    "val_labels['label'] = True\n",
    "val_bbox['bbox'] = True\n",
    "val_download['download'] = True\n",
    "\n",
    "df_val_imgs = (val_download.merge(val_labels, on='ImageID', how='outer')\n",
    "                           .merge(val_bbox, on='ImageID', how='outer'))\n",
    "df_val_imgs.fillna(False, inplace=True)\n",
    "\n",
    "# joining test dfs\n",
    "test_labels['label'] = True\n",
    "test_bbox['bbox'] = True\n",
    "test_download['download'] = True\n",
    "\n",
    "df_test_imgs = (test_download.merge(test_labels, on='ImageID', how='outer')\n",
    "                             .merge(test_bbox, on='ImageID', how='outer'))\n",
    "df_test_imgs.fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ref = {'Train': df_train_imgs, 'Validation': df_val_imgs, 'Test': df_test_imgs}\n",
    "\n",
    "for label, df in ref.items():\n",
    "    not_down = df[df.download == False].shape[0]\n",
    "    not_label = df[(df.download == True) & (df.label == False)].shape[0]\n",
    "    not_bbox = df[(df.download == True) & (df.bbox == False)].shape[0]\n",
    "    label_not_bbox = df[(df.download == True) \n",
    "                        & (df.label == True)\n",
    "                        & (df.bbox == False)].shape[0]\n",
    "    bbox_not_label = df[(df.download == True) \n",
    "                        & (df.label == False)\n",
    "                        & (df.bbox == True)].shape[0]\n",
    "    \n",
    "    print(f\"About {label} data:\")\n",
    "    print(f\"   There are {not_down} images not downloaded\")\n",
    "    print(f\"   There are {not_label} images without label\")\n",
    "    print(f\"   There are {not_bbox} images without bounding boxes identified\")\n",
    "    print(f\"   There are {label_not_bbox} images with labels in image level, but without bounding boxes\")\n",
    "    print(f\"   There are {bbox_not_label} images without labels in image level, but having bounding boxes\", end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Removing duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_bbox_raw = df_train_bbox_raw.drop_duplicates()\n",
    "df_train_bbox_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Adding semantic class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def semantic_label(df):\n",
    "    return (df.merge(df_classes_raw,\n",
    "                     left_on='LabelName',\n",
    "                     right_on='class_encode',\n",
    "                     how='inner')\n",
    "              .drop(['class_encode'], axis=1)\n",
    "              .rename(columns={'class_name': 'LabelSemantic'}))\n",
    "\n",
    "df_train_bbox   = semantic_label(df_train_bbox_raw)\n",
    "df_train_labels = semantic_label(df_train_labels_raw)\n",
    "df_val_bbox     = semantic_label(df_val_bbox_raw)\n",
    "df_val_labels   = semantic_label(df_val_labels_raw)\n",
    "df_test_bbox    = semantic_label(df_test_bbox_raw)\n",
    "df_test_labels  = semantic_label(df_test_labels_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Naming the first class in the hierarchy\n",
    "\n",
    "As I shown, the first node in the JSON hierarchy has no name. I am going to define it as \"Entity\" in the `df_classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_classes = pd.concat([pd.DataFrame([['/m/0bl9f', 'Entity']],\n",
    "                                     columns=['class_encode', 'class_name']),\n",
    "                        df_classes_raw],\n",
    "                       ignore_index=True)\n",
    "df_classes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Creating a semantic dictionary of hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def changing_to_semantic(tree, *args):\n",
    "    try:\n",
    "        tree['LabelName'] = utils.semantic_name(tree['LabelName'])\n",
    "    except KeyError:\n",
    "        tree['LabelName'] = 'Entity'\n",
    "    \n",
    "    if 'Subcategory' in tree.keys():\n",
    "        for subcat in tree['Subcategory']:\n",
    "            changing_to_semantic(subcat, *args, tree['LabelName'])\n",
    "\n",
    "\n",
    "dict_semantic_hierarchy = deepcopy(dict_hierarchy_raw)\n",
    "changing_to_semantic(dict_semantic_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"The first node class encode is:\",\n",
    "      dict_semantic_hierarchy['LabelName'], end=\"\\n\"*2)\n",
    "\n",
    "# defining a node to consult\n",
    "i=17\n",
    "\n",
    "print(f\"the {i}th son encode of the first node:\",\n",
    "      dict_semantic_hierarchy['Subcategory'][i]['LabelName'])\n",
    "print(f\"The sons of the {i}th node:\")\n",
    "for subcat in dict_semantic_hierarchy['Subcategory'][i]['Subcategory']:\n",
    "    print(f\"   {subcat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the hierarchy dictionary in a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding in images DF path to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation is going to be very useful to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = utils.tabularize_hierarchy_dict(dict_semantic_hierarchy, df_classes)\n",
    "\n",
    "df_enriched_classes = pd.DataFrame(rows,\n",
    "                                   columns=['Id', 'Label', 'IdParent', \n",
    "                                            'LabelParent', 'Depth', 'Leaf'])\n",
    "\n",
    "df_enriched_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of questions that I want to dive into in this EDA. Each topic is going to be about one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes Analysis\n",
    "\n",
    "For the first step, it is going to render a visualization of all classes in the dataset, and how they are connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# generating images for report\n",
    "print(\"creating figures to analysis report...\")\n",
    "\n",
    "img_path = os.path.join(\".\", \"capstone\", \"images\")\n",
    "\n",
    "df = df_enriched_classes\n",
    "\n",
    "def save_img_sankey(df, height, width, img_name, title, pos_leg):\n",
    "    print(f\"Creating image '{img_name}'...\", end='')\n",
    "    df_l1 = df[(df.Depth == 1)]\n",
    "    \n",
    "    orca.config.default_height = height\n",
    "    orca.config.default_width = width\n",
    "    \n",
    "    (visuals.sankey(df, height, width, df_enriched_classes, title,\n",
    "                    pos_leg=pos_leg)\n",
    "            .write_image(os.path.join(img_path, img_name)))\n",
    "    print('Ok!')\n",
    "\n",
    "# img with depth 1\n",
    "df_final = df[(df.Depth == 1)]\n",
    "\n",
    "save_img_sankey(df_final, 1200, 600, \"lvl1_classes.png\",\n",
    "                'Classes Hierarchy with max distance of 1 node',\n",
    "                pos_leg=[[0.15, 0.95], [0.15, 0.927]])\n",
    "\n",
    "\n",
    "# img with depth 2 - pt1\n",
    "l2_sep_cat = ['Telehone', 'Kitchenware', 'Cosmetics', 'Clock', \n",
    "              'Auto part', 'Furniture', 'Musical instrument', 'Home appliance',\n",
    "              'Food', 'Clothing', 'Telephone', 'Plumbing fixture', 'Drink']\n",
    "l2 = df[(df.Depth == 2) & (df.LabelParent.isin(l2_sep_cat))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2])\n",
    "save_img_sankey(df_final, 1400, 650, \"lvl2_classes_pt1.png\",\n",
    "                'Classes Hierarchy with max distance of 2 nodes - part 1',\n",
    "                pos_leg=[[0.15, 0.9], [0.15, 0.880]])\n",
    "\n",
    "\n",
    "# img with depth 2 - pt2\n",
    "l2 = df[(df.Depth == 2) & (~df.LabelParent.isin(l2_sep_cat))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2])\n",
    "save_img_sankey(df_final, 1400, 650, \"lvl2_classes_pt2.png\",\n",
    "                'Classes Hierarchy with max distance of 2 nodes - part 2',\n",
    "                pos_leg=[[0.15, 0.9], [0.15, 0.880]])\n",
    "\n",
    "# img with depth 3 - pt1\n",
    "l3_sep_cat = ['Land vehicle', 'Watercraft', 'Aircraft', 'Bed', 'Couch',\n",
    "              'Table', 'Mammal', 'Reptile', 'Invertebrate', 'Bird',\n",
    "              'Shellfish', 'Fish', 'Tree', 'Flower']\n",
    "l3 = df[(df.Depth == 3) & (df.LabelParent.isin(l3_sep_cat))]\n",
    "l2 = df[(df.Depth == 2) & (df.Label.isin(l3.LabelParent.unique()))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2, l3])\n",
    "save_img_sankey(df_final, 1400, 750, \"lvl3_classes_pt1.png\",\n",
    "                'Classes Hierarchy with max distance of 3 nodes - part 1',\n",
    "                pos_leg=[[0.12, 0.9], [0.12, 0.880]])\n",
    "\n",
    "# img with depth 3 - pt2\n",
    "l3 = df[(df.Depth == 3) & (~df.LabelParent.isin(l3_sep_cat))]\n",
    "l2 = df[(df.Depth == 2) & (df.Label.isin(l3.LabelParent.unique()))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2, l3])\n",
    "save_img_sankey(df_final, 1400, 750, \"lvl3_classes_pt2.png\",\n",
    "                'Classes Hierarchy with max distance of 3 nodes - part 2',\n",
    "                pos_leg=[[0.12, 0.9], [0.12, 0.880]])\n",
    "\n",
    "# img with depth 4\n",
    "l4 = df[(df.Depth == 4)]\n",
    "l3 = df[(df.Depth == 3) & (df.Label.isin(l4.LabelParent.unique()))]\n",
    "l2 = df[(df.Depth == 2) & (df.Label.isin(l3.LabelParent.unique()))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2, l3, l4])\n",
    "save_img_sankey(df_final, 700, 750, \"lvl4_classes.png\",\n",
    "                'Classes Hierarchy with max distance of 4 nodes',\n",
    "                pos_leg=[[0.1, 0.93], [0.1, 0.887]])\n",
    "\n",
    "# img with depth 5\n",
    "l5 = df[(df.Depth == 5)]\n",
    "l4 = df[(df.Depth == 4) & (df.Label.isin(l5.LabelParent.unique()))]\n",
    "l3 = df[(df.Depth == 3) & (df.Label.isin(l4.LabelParent.unique()))]\n",
    "l2 = df[(df.Depth == 2) & (df.Label.isin(l3.LabelParent.unique()))]\n",
    "l1 = df[(df.Depth == 1) & (df.Label.isin(l2.LabelParent.unique()))]\n",
    "\n",
    "df_final = pd.concat([l1, l2, l3, l4, l5])\n",
    "save_img_sankey(df_final, 275, 1000, \"lvl5_classes.png\",\n",
    "                'Classes Hierarchy with max distance of 5 nodes',\n",
    "                pos_leg=[[0.1, 1.2], [0.1, 0.95]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot a global sankey visualization\n",
    "(visuals.sankey(df_enriched_classes, 5500, 800, df_enriched_classes,\n",
    "                'Showing Hierarchy of all classes',\n",
    "                pos_leg=[[0.05, 0.985], [0.05, 0.981]])\n",
    "        .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Ambiguous Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some classes have an ambiguous path, more than one parent. Because of that, we can not, for sure, say who is the parent of some node. The following visualization show this fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sankey_ambiguous_node(node):\n",
    "    df = df_enriched_classes\n",
    "    \n",
    "    lowest = df[df.Label == node]\n",
    "    l1 = df[df.Label.isin(lowest.LabelParent.unique())]\n",
    "    l2 = df[df.Label.isin(l1.LabelParent.unique())]\n",
    "    l3 = df[df.Label.isin(l2.LabelParent.unique())]\n",
    "    l4 = df[df.Label.isin(l3.LabelParent.unique())]\n",
    "    l5 = df[df.Label.isin(l4.LabelParent.unique())]\n",
    "\n",
    "    df_final = pd.concat([lowest, l1, l2, l3, l4, l5])\n",
    "    \n",
    "    fig = (visuals.sankey(df_final, 250, 700, df_enriched_classes,\n",
    "                          f\"Ambiguous Path: {node}\", pad=20,\n",
    "                          pos_leg=[[1.08, 0.82], [1.08, 0.28]]))\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "sankey_ambiguous_node('Shrimp')\n",
    "sankey_ambiguous_node('Spoon')\n",
    "sankey_ambiguous_node('Knife')\n",
    "sankey_ambiguous_node('Wheelchair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Union DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bbox['Type'] = 'Train'\n",
    "df_train_labels['Type'] = 'Train'\n",
    "df_images_train['Type'] = 'Train'\n",
    "\n",
    "df_val_bbox['Type'] = 'Cross-Val'\n",
    "df_val_labels['Type'] = 'Cross-Val'\n",
    "df_images_val['Type'] = 'Cross-Val'\n",
    "\n",
    "df_test_bbox['Type'] = 'Test'\n",
    "df_test_labels['Type'] = 'Test'\n",
    "df_images_test['Type'] = 'Test'\n",
    "\n",
    "df_labels = pd.concat([df_train_labels, df_val_labels, df_test_labels])\n",
    "df_bbox = pd.concat([df_train_bbox, df_val_bbox, df_test_bbox])\n",
    "df_images = pd.concat([df_images_train, df_images_test, df_images_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.sample(4, random_state=84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Label-Level Confidence plots\n",
    "feature = 'Confidence'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_labels, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [120000, 150000, 300000, 1000000, 3000000, 6000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000)}{'M' if y/1000>=1000 else 'K'}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"Label-Level: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, ['Confidence 0', 'Confidence 1'],\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, ['Confidence 0', 'Confidence 1'],\n",
    "                    *percs.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Label-Level Confidence Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = 'Confidence == 1'\n",
    "\n",
    "imgs = df_labels.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_imgs(imgs, ax, df_images)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = 'Confidence == 0'\n",
    "\n",
    "imgs = df_labels.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_imgs(imgs, ax, df_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Label-Level Source plots\n",
    "feature = 'Source'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_labels, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [300, 1000, 10000, 100000, 300000, 1000000, 3000000, 10000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"Label-Level: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *list(counts.values()))\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Label-Level Confidence Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = \"Source == 'verification' and Confidence == 1\"\n",
    "\n",
    "imgs = df_labels.query(query).sample(4, random_state=43)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_imgs(imgs, ax, df_images)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = \"Source == 'crowdsource-verification' and Confidence == 1\"\n",
    "\n",
    "imgs = df_labels.query(query).sample(4, random_state=43)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_imgs(imgs, ax, df_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbox.sample(4, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Positions distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# BoudingBox Positions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6), sharex=True, sharey=True)\n",
    "\n",
    "fig.suptitle('Positions', fontsize=18)\n",
    "\n",
    "axes[0, 0].hist(df_bbox.XMin)\n",
    "axes[0, 0].set_ylabel('#counts')\n",
    "axes[0, 0].set_title('left-edge')\n",
    "\n",
    "axes[1, 0].hist(df_bbox.XMax)\n",
    "axes[1, 0].set_ylabel('#counts')\n",
    "axes[1, 0].set_xlabel('% of the image width')\n",
    "axes[1, 0].set_title('right-edge')\n",
    "\n",
    "axes[0, 1].hist(df_bbox.YMin)\n",
    "axes[0, 1].set_title('bottom-edge')\n",
    "\n",
    "axes[1, 1].hist(df_bbox.YMax)\n",
    "axes[1, 1].set_title('top-edge')\n",
    "axes[1, 1].set_xlabel('% of the image height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# size distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "\n",
    "fig.suptitle('Size', fontsize=18)\n",
    "\n",
    "axes[0].hist(df_bbox.XMax - df_bbox.XMin)\n",
    "axes[0].set_title('bbox width')\n",
    "axes[0].set_ylabel('#counts')\n",
    "axes[0].set_xlabel('% of the image width')\n",
    "\n",
    "axes[1].hist(df_bbox.YMax - df_bbox.YMin)\n",
    "axes[1].set_xlabel('bbox height')\n",
    "axes[1].set_title('% of the image height');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Confidence plots\n",
    "feature = 'Confidence'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox Source plots\n",
    "feature = 'Source'\n",
    "import matplotlib as mpl\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "yticks = [100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('symlog')\n",
    "ax[0].set_ylim(100000, 18000000)\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox Source Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = \"Source == 'xclick'\"\n",
    "\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox, print_others=False)\n",
    "\n",
    "# BBox Source Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = \"Source == 'activemil'\"\n",
    "\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"Image-level: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox, print_others=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IsOccluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox IsOccluded plots\n",
    "feature = 'IsOccluded'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "figure, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [20000, 30000, 100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "figure.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# BBox IsOccluded Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "feature = \"IsOccluded\"\n",
    "\n",
    "# 1\n",
    "query = f\"{feature} == 1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == 0\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# -1\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == -1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IsTruncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox IsTruncated plots\n",
    "feature = 'IsTruncated'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [20000, 30000, 100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBox IsTruncated Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "feature = \"IsTruncated\"\n",
    "\n",
    "# 1\n",
    "query = f\"{feature} == 1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == 0\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# -1\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == -1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IsGroupOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# BBox IsGroupOf plots\n",
    "feature = 'IsGroupOf'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [20000, 30000, 100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox IsGroupOf Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "feature = \"IsGroupOf\"\n",
    "\n",
    "# 1\n",
    "query = f\"{feature} == 1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == 0\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# -1\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == -1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IsDepiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# BBox IsDepiction plots\n",
    "feature = 'IsDepiction'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [20000, 30000, 100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox IsDepiction Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "feature = \"IsDepiction\"\n",
    "\n",
    "# 1\n",
    "query = f\"{feature} == 1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == 0\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# -1\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == -1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IsInside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# BBox IsInside plots\n",
    "feature = 'IsInside'\n",
    "\n",
    "# prepare date\n",
    "labels, counts, percs = utils.amount_and_percentage(df_bbox, feature)\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "\n",
    "yticks = [20000, 30000, 100000, 300000, 1000000, 3000000, 10000000, 15000000]\n",
    "ylabels = [f\"{int(y/1000000 if y/1000>=1000 else y/1000 if y>=1000 else y)}\"\\\n",
    "           f\"{'M' if y/1000>=1000 else 'K' if y>=1000 else ''}\"\n",
    "           for y in yticks]\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_yticks(yticks)\n",
    "ax[0].set_yticklabels(ylabels)\n",
    "\n",
    "fig.suptitle(f\"BBox: {feature}\", fontsize=20)\n",
    "\n",
    "visuals.barplot(ax[0], f\"Total amount\",\n",
    "                labels, list(counts.keys()),\n",
    "                *counts.values())\n",
    "\n",
    "visuals.stacked_bar(ax[1], f'Percentage',\n",
    "                    labels, list(percs.keys()),\n",
    "                    *list(percs.values()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# BBox IsInside Images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "feature = \"IsInside\"\n",
    "\n",
    "# 1\n",
    "query = f\"{feature} == 1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == 0\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)\n",
    "\n",
    "# -1\n",
    "fig, ax = plt.subplots(2, 2, figsize=(13, 8))\n",
    "\n",
    "query = f\"{feature} == -1\"\n",
    "imgs = df_bbox.query(query).sample(4, random_state=13)\n",
    "\n",
    "fig.suptitle(f\"BBox: {query}\", fontsize=20)\n",
    "visuals.show_bbox(imgs, ax, df_images, df_bbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "324px",
    "width": "266px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
